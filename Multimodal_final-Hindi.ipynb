{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15cba77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "label_map = {\n",
    "    'affected_individuals': 0,\n",
    "    'infrastructure_and_utility_damage': 1,\n",
    "    'not_humanitarian': 2,\n",
    "    'other_relevant_information': 3,\n",
    "    'rescue_volunteering_or_donation_effort': 4,\n",
    "    'vehicle_damage': 1,\n",
    "    'injured_or_dead_people': 0,\n",
    "    'missing_or_found_people': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f703ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPZLoader(Dataset):\n",
    "    def __init__(self, img_embed_filename,text_emb_filename,tsv_file, transform=None):\n",
    "#        self.files = list(Path(path).glob('*/*.npz'))\n",
    "#        self.transform = transform\n",
    "        self.text_embed = torch.load(text_embed_filename).mean(axis=1) # ../sporwal9/eng_test_data_emb.pt\n",
    "        self.img_emb = np.load(img_embed_filename) #image_model_ouputs/resnet18_image_embedding_512_test.npz\n",
    "        self.original_df = pd.read_csv(tsv_file, sep='\\t') #'../sverma324/data/crisis-mmd/task_humanitarian_text_img_train.tsv'\n",
    "        self.df = self.original_df.loc[original_df.label_text_image==\"Positive\"]\n",
    "        id_list=  list(self.df['tweet_id'].unique())\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_tweetID = self.img_emb['image_tweetID'][idx]\n",
    "        \n",
    "        image_embedding = torch.from_numpy(self.img_emb['image_embedding'][idx].squeeze(1))\n",
    "        \n",
    "        text_embedding = self.text_embed[idx].unsqueeze(1)\n",
    "        fusion_emb = torch.cat((text_embedding.cuda(),image_embedding.cuda()),dim=0)\n",
    "        label = self.df.loc[self.df['tweet_id']==image_tweetID,'label'][0]\n",
    "        if image_tweetID in id_list :\n",
    "            return fusion_emb,image_tweetID,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518b5e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlignFormatLabels(list, labels):\n",
    "    aligned_list = []\n",
    "    for item in list:\n",
    "        if item == 'vehicle_damage':\n",
    "            aligned_list.append('infrastructure_and_utility_damage')\n",
    "        elif item == 'missing_or_found_people' or item == 'injured_or_dead_people':\n",
    "            aligned_list.append('affected_individuals')\n",
    "        else:\n",
    "            aligned_list.append(item)\n",
    "    final_labels = []\n",
    "    for item in aligned_list:\n",
    "        final_labels.append(labels.index(item))\n",
    "    return final_labels\n",
    "\n",
    "my_labels = ['other_relevant_information', 'affected_individuals', 'rescue_volunteering_or_donation_effort', \n",
    "             'infrastructure_and_utility_damage', 'not_humanitarian']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa033932",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74eb7b11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13608, 9), (2237, 9), (2237, 9))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tsv_file = '../sverma324/data/crisis-mmd/task_humanitarian_text_img_test.tsv'\n",
    "train_tsv_file = '../sverma324/data/crisis-mmd/task_humanitarian_text_img_train.tsv'\n",
    "val_tsv_file = '../sverma324/data/crisis-mmd/task_humanitarian_text_img_dev.tsv'\n",
    "\n",
    "df_test = pd.read_csv(test_tsv_file, sep='\\t')\n",
    "df_train = pd.read_csv(train_tsv_file, sep='\\t')\n",
    "df_val = pd.read_csv(val_tsv_file, sep='\\t')\n",
    "\n",
    "df_train.shape, df_test.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c6df4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "      <th>label_image</th>\n",
       "      <th>label_text_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>california_wildfires</td>\n",
       "      <td>917791291823591425</td>\n",
       "      <td>917791291823591425_1</td>\n",
       "      <td>RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...</td>\n",
       "      <td>data_image/california_wildfires/10_10_2017/917...</td>\n",
       "      <td>not_humanitarian</td>\n",
       "      <td>other_relevant_information</td>\n",
       "      <td>not_humanitarian</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>california_wildfires</td>\n",
       "      <td>917791291823591425</td>\n",
       "      <td>917791291823591425_0</td>\n",
       "      <td>RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...</td>\n",
       "      <td>data_image/california_wildfires/10_10_2017/917...</td>\n",
       "      <td>other_relevant_information</td>\n",
       "      <td>other_relevant_information</td>\n",
       "      <td>infrastructure_and_utility_damage</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             event_name            tweet_id              image_id   \n",
       "0  california_wildfires  917791291823591425  917791291823591425_1  \\\n",
       "1  california_wildfires  917791291823591425  917791291823591425_0   \n",
       "\n",
       "                                          tweet_text   \n",
       "0  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...  \\\n",
       "1  RT @Cal_OES: PLS SHARE: Weâ€™re capturing wild...   \n",
       "\n",
       "                                               image   \n",
       "0  data_image/california_wildfires/10_10_2017/917...  \\\n",
       "1  data_image/california_wildfires/10_10_2017/917...   \n",
       "\n",
       "                        label                  label_text   \n",
       "0            not_humanitarian  other_relevant_information  \\\n",
       "1  other_relevant_information  other_relevant_information   \n",
       "\n",
       "                         label_image label_text_image  \n",
       "0                   not_humanitarian         Negative  \n",
       "1  infrastructure_and_utility_damage         Negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f33853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955 6126\n"
     ]
    }
   ],
   "source": [
    "# get training labels in right format\n",
    "raw_train_labels = df_train[df_train.label_text_image == \"Positive\"][\"label_text\"]\n",
    "train_labels = torch.Tensor(AlignFormatLabels(raw_train_labels, my_labels))\n",
    "\n",
    "# get testing labels in right format\n",
    "raw_test_labels = df_test[df_test.label_text_image == \"Positive\"][\"label_text\"]\n",
    "test_labels = torch.Tensor(AlignFormatLabels(raw_test_labels, my_labels))\n",
    "\n",
    "train_labels.to(\"cuda\")\n",
    "test_labels.to(\"cuda\")\n",
    "\n",
    "print(len(test_labels), len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9af3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_ids_train = df_train.loc[df_train.label_text_image==\"Positive\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2b78fc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_emb_test_raw = torch.load('../sporwal9/hindi_test_data_emb.pt')\n",
    "text_emb_train_raw = torch.load('../sporwal9/hindi_train_data_emb.pt')\n",
    "# text_emb_val_raw = torch.load('../sporwal9/eng_dev_data_emb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b761c6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text_emb_test = text_emb_test_raw.mean(axis=1).squeeze(1)\n",
    "text_emb_train = text_emb_train_raw.mean(axis=1).squeeze(1)\n",
    "# text_emb_val = text_emb_val_raw.mean(axis=1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6373a242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([955, 256]), torch.Size([6126, 256]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_emb_test.shape, text_emb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ac41dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_emb_test_raw = np.load(\"image_model_ouputs/resnet18_image_embedding_512_test.npz\")\n",
    "img_emb_train_raw = np.load(\"image_model_ouputs/resnet18_image_embedding_512_train.npz\")\n",
    "# img_emb_val_raw = np.load(\"image_model_ouputs/resnet18_image_embedding_512_dev.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c4c9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_emb_test, img_tweetID_test = img_emb_test_raw['image_embedding'], img_emb_test_raw['image_tweetID']\n",
    "img_emb_train, img_tweetID_train = img_emb_train_raw['image_embedding'], img_emb_train_raw['image_tweetID']\n",
    "# img_emb_val, img_tweetID_val = img_emb_val_raw['image_embedding'], img_emb_val_raw['image_tweetID']\n",
    "\n",
    "img_emb_test = torch.from_numpy(img_emb_test[0:955]).squeeze((2,3))\n",
    "img_emb_train = torch.from_numpy(img_emb_train[0:13608]).squeeze((2,3))\n",
    "# img_emb_val = torch.from_numpy(img_emb_val).squeeze((2,3))\n",
    "\n",
    "img_emb_train = img_emb_train[positive_ids_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c97beca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([955, 512]), torch.Size([6126, 512]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_emb_test.shape, img_emb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3ead626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((955,), (13608,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tweetID_test.shape, img_tweetID_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3913d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.cat((text_emb_train.cuda(), img_emb_train.cuda()), dim=1)\n",
    "X_test = torch.cat((text_emb_test.cuda(), img_emb_test.cuda()), dim=1)\n",
    "\n",
    "# train_dataset = DatasetFormatting(X_train, train_labels)\n",
    "# test_dataset = DatasetFormatting(X_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16ebb71a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6126, 768]), torch.Size([955, 768]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade2caa",
   "metadata": {},
   "source": [
    "## Multimodal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc7d1c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 512 128 32 5\n"
     ]
    }
   ],
   "source": [
    "in_features = 600\n",
    "h1 = 512\n",
    "h2 = 128\n",
    "h3 = 32\n",
    "out_features = 5\n",
    "\n",
    "print(in_features, h1, h2, h3, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "357b700e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multimodal(\n",
       "  (multimodal): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=600, bias=True)\n",
       "    (1): Dropout(p=0, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=600, out_features=512, bias=True)\n",
       "    (4): Dropout(p=0, inplace=False)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (7): Dropout(p=0, inplace=False)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (10): Dropout(p=0, inplace=False)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=32, out_features=5, bias=True)\n",
       "    (13): Dropout(p=0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Multimodal(torch.nn.Module):\n",
    "    def __init__(self, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.multimodal = torch.nn.Sequential(\n",
    "            # input layer\n",
    "            torch.nn.Linear(X_train.shape[1], in_features),\n",
    "            # dropout\n",
    "            torch.nn.Dropout(dropout),\n",
    "            # ReLU activation\n",
    "            torch.nn.ReLU(),\n",
    "            # hidden_layer1\n",
    "            torch.nn.Linear(in_features, h1),\n",
    "            # dropout\n",
    "            torch.nn.Dropout(dropout),\n",
    "            # ReLU activation\n",
    "            torch.nn.ReLU(),\n",
    "            # hidden_layer2\n",
    "            torch.nn.Linear(h1, h2),\n",
    "            # dropout\n",
    "            torch.nn.Dropout(dropout),\n",
    "            # ReLU activation\n",
    "            torch.nn.ReLU(),\n",
    "            # hidden_layer3\n",
    "            torch.nn.Linear(h2, h3),\n",
    "            # dropout\n",
    "            torch.nn.Dropout(dropout),\n",
    "            # ReLU activation\n",
    "            torch.nn.ReLU(),\n",
    "            # output layer\n",
    "            torch.nn.Linear(h3, out_features),\n",
    "            # dropout\n",
    "            torch.nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.multimodal(x)\n",
    "    \n",
    "multimodal = Multimodal(dropout=0)\n",
    "multimodal.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9036c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "batch_size = 100\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(multimodal.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "084ba10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 1.1908745443180502\n",
      "Finished epoch 1, latest loss 1.2009073891087094\n",
      "Finished epoch 2, latest loss 1.1821755265571174\n",
      "Finished epoch 3, latest loss 1.14221614933916\n",
      "Finished epoch 4, latest loss 1.1807659710167397\n",
      "Finished epoch 5, latest loss 1.1188481698875992\n",
      "Finished epoch 6, latest loss 1.083681136043518\n",
      "Finished epoch 7, latest loss 0.9885141687455621\n",
      "Finished epoch 8, latest loss 0.9193524472064151\n",
      "Finished epoch 9, latest loss 0.9226230566882219\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        Xbatch = X_train[i:i+batch_size]\n",
    "        y_pred = multimodal(Xbatch).type(torch.float64).to(\"cuda\")\n",
    "        ybatch = train_labels[i:i+batch_size].type(torch.LongTensor).to(\"cuda\")\n",
    "        loss = criterion(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "381073a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aab8ffb4c10>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArKUlEQVR4nO3deXgV5d3/8fc3C2ELhCXsuyLIJiKCqEXcEa1aa1utba2tRa39PXZ56tZdu1jt49On1WqtdWsVrbtV3HEXhbAKAoLIEgIhLCEJIWT7/v44k+NJJgkhi0mmn9d1nStnZu4zc9/JyefM3HPPGXN3REQkupJauwIiItKyFPQiIhGnoBcRiTgFvYhIxCnoRUQiLqW1K1Cb3r17+7Bhw1q7GiIi7caiRYt2uHtmbcvaZNAPGzaMrKys1q6GiEi7YWYb61qmrhsRkYhT0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIi5yQT9vdS45+ftauxoiIm1G5IL+W/dlcfZtb7d2NURE2ozIBT3AjqLS1q6CiEibEcmgFxGRTx0w6M1ssJm9ZmarzGylmV0VzO9pZi+b2drgZ486Xj/TzNaY2Tozu7a5GyAiIvVryB59OfAjdz8cOAa40szGANcCr7r7SODVYLoaM0sGbgfOAMYAFwavFRGRz8gBg97dt7r74uB5IbAKGAicA9wfFLsfOLeWl08B1rn7encvBR4OXiciIp+Rg+qjN7NhwJHA+0Bfd98KsQ8DoE8tLxkIbE6Yzg7m1bbu2WaWZWZZeXl5B1MtERGpR4OD3sy6Ao8D33f3goa+rJZ5XltBd7/L3Se7++TMzFq/O19ERBqhQUFvZqnEQv5Bd38imJ1rZv2D5f2B7bW8NBsYnDA9CMhpfHVFRORgNWTUjQF/B1a5+60Ji54BLg6eXww8XcvLFwIjzWy4mXUALgheJyIin5GG7NEfB3wdOMnMlgaPWcBNwKlmthY4NZjGzAaY2VwAdy8Hvge8SOwk7r/cfWULtINgey21ahGRduuA94x197epva8d4ORayucAsxKm5wJzG1tBERFpmkhdGasdehGRsGgFfWtXQESkDYpU0IuISFikgl4nY0VEwqIV9K1dARGRNihaQa+kFxEJiVTQi4hIWKSC3tV5IyISEq2gV86LiIREKuhFRCRMQS8iEnGRCnp13YiIhEUq6EVEJCxSQa9RNyIiYdEKeuW8iEjIAb+P3szuAc4Ctrv7uGDeI8CooEgGkO/uE2t57QagEKgAyt19crPUWkREGuyAQQ/cB9wGPFA1w92/UvXczP4H2FPP60909x2NreDB0A69iEhYQ+4w9aaZDattWXA/2S8DJzVzvRpF314pIhLW1D76zwG57r62juUOvGRmi8xsdn0rMrPZZpZlZll5eXlNrJaIiFRpatBfCMypZ/lx7j4JOAO40sym11XQ3e9y98nuPjkzM7NRldH+vIhIWKOD3sxSgPOAR+oqE9woHHffDjwJTGns9hpCPTciImFN2aM/BVjt7tm1LTSzLmaWXvUcOA1Y0YTtiYhIIxww6M1sDjAfGGVm2Wb27WDRBdTotjGzAWY2N5jsC7xtZsuABcBz7v5C81W9FtqjFxEJaciomwvrmP/NWublALOC5+uBI5pYv4OiK2NFRMIidWWsiIiERSrodTJWRCQsWkHf2hUQEWmDIhX0IiISFqmg11cgiIiERSvoW7sCIiJtUKSCXkREwiIV9Oq5EREJi1bQq/NGRCQkUkEvIiJh0Qp67dCLiIREKuiV8yIiYZEKehERCYtU0GvUjYhIWLSCXp03IiIhDbnxyD1mtt3MViTM+6WZbTGzpcFjVh2vnWlma8xsnZld25wVFxGRhmnIHv19wMxa5v+vu08MHnNrLjSzZOB2YjcGHwNcaGZjmlLZA1HXjYhI2AGD3t3fBHY1Yt1TgHXuvt7dS4GHgXMasZ4GU86LiIQ1pY/+e2a2POja6VHL8oHA5oTp7GBercxstpllmVlWXl5eoyqkb68UEQlrbNDfARwCTAS2Av9TSxmrZV6dSezud7n7ZHefnJmZ2chqiYhITY0KenfPdfcKd68E/kasm6ambGBwwvQgIKcx22t4vVpy7SIi7VOjgt7M+idMfgFYUUuxhcBIMxtuZh2AC4BnGrM9ERFpvJQDFTCzOcAMoLeZZQO/AGaY2URiXTEbgMuCsgOAu919lruXm9n3gBeBZOAed1/ZEo0QEZG6HTDo3f3CWmb/vY6yOcCshOm5QGjoZUtR142ISJiujBURibhIBb2IiIRFKujVdSMiEhatoG/tCoiItEGRCnoREQmLVNDrKxBERMKiFfStXQERkTYoUkEvIiJhkQp69dyIiIRFKujVeSMiEhaxoBcRkZoiFfTquhERCYtW0Ld2BURE2qBIBb2IiIRFKujVdSMiEnbAoA9u/r3dzFYkzLvFzFYHNwd/0swy6njtBjP7wMyWmllWM9a7VvqaYhGRsIbs0d8HzKwx72VgnLtPAD4Crqvn9Se6+0R3n9y4KoqISFMcMOjd/U1gV415L7l7eTD5HrEbf7c6dd2IiIQ1Rx/9t4Dn61jmwEtmtsjMZte3EjObbWZZZpaVl5fXqIoo6EVEwpoU9Gb2E6AceLCOIse5+yTgDOBKM5te17rc/S53n+zukzMzM5tSLRERSdDooDezi4GzgIu8ju8HDm4WjrtvB54EpjR2ew2hk7EiImGNCnozmwlcA5zt7sV1lOliZulVz4HTgBW1lW0u6roREQlryPDKOcB8YJSZZZvZt4HbgHTg5WDo5J1B2QFmNjd4aV/gbTNbBiwAnnP3F1qkFSIiUqeUAxVw9wtrmf33OsrmALOC5+uBI5pUOxERaTJdGSsiEnGRCnoREQmLVNBr1I2ISFi0gl45LyISEqmgFxGRsEgFvXboRUTCohX06rsREQmJVtC3dgVERNqgSAW9iIiERSro1XMjIhIWqaBX542ISFjEgl5ERGqKVNCr60ZEJCxaQd/aFRARaYMiFfQiIhLWkBuP3GNm281sRcK8nmb2spmtDX72qOO1M81sjZmtM7Nrm7PitVHXjYhIWEP26O8DZtaYdy3wqruPBF4Npqsxs2TgdmI3Bh8DXGhmY5pU2wPQlbEiImEHDHp3fxPYVWP2OcD9wfP7gXNreekUYJ27r3f3UuDh4HUiIvIZamwffV933woQ/OxTS5mBwOaE6exgXovR/ryISFhLnoy1WubVmcVmNtvMsswsKy8vr1EbVM+NiEhYY4M+18z6AwQ/t9dSJhsYnDA9CMipa4Xufpe7T3b3yZmZmY2sloiI1NTYoH8GuDh4fjHwdC1lFgIjzWy4mXUALghe12J0K0ERkbCGDK+cA8wHRplZtpl9G7gJONXM1gKnBtOY2QAzmwvg7uXA94AXgVXAv9x9Zcs0I6CcFxEJSTlQAXe/sI5FJ9dSNgeYlTA9F5jb6NqJiEiTRerKWO3Qi4iERSvolfQiIiGRCnoREQmLVNBr1I2ISFi0gl45LyISEqmgFxGRsEgFvXboRUTCohX06rsREQmJVNCLiEhYpIJe+/MiImGRCnolvYhIWLSCXkREQiIV9LpgSkQkLFpBr5wXEQmJVNCLiEhYpIJee/QiImGNDnozG2VmSxMeBWb2/RplZpjZnoQyP29yjeuhnBcRCTvgHabq4u5rgIkAZpYMbAGerKXoW+5+VmO3IyIiTdNcXTcnAx+7+8ZmWl+j6CsQRETCmivoLwDm1LFsmpktM7PnzWxsXSsws9lmlmVmWXl5eY2qhGJeRCSsyUFvZh2As4FHa1m8GBjq7kcAfwaeqms97n6Xu09298mZmZmNqot26EVEwppjj/4MYLG759Zc4O4F7l4UPJ8LpJpZ72bYpoiINFBzBP2F1NFtY2b9zMyC51OC7e1shm3WQbv0IiI1NXrUDYCZdQZOBS5LmHc5gLvfCZwPXGFm5cA+4AJvwTOm6roREQlrUtC7ezHQq8a8OxOe3wbc1pRtiIhI00TrytjWroCISBsUraBX0ouIhEQq6EVEJCxSQa/voxcRCYtW0CvnRURCIhX0IiISFqmg1w69iEhYtIJefTciIiGRCnoREQlT0IuIRFykgl49NyIiYZEKehERCYtU0OuCKRGRsGgFvXJeRCQkUkEvIiJhTQp6M9tgZh+Y2VIzy6pluZnZn8xsnZktN7NJTdnegWiPXkQkrEk3Hgmc6O476lh2BjAyeEwF7gh+tgjlvIhIWEt33ZwDPOAx7wEZZta/hbcpIiIJmhr0DrxkZovMbHYtywcCmxOms4N5IWY228yyzCwrLy+vcZVR342ISEhTg/44d59ErIvmSjObXmO51fKaWtPY3e9y98nuPjkzM7NRlVHMi4iENSno3T0n+LkdeBKYUqNINjA4YXoQkNOUbYqIyMFpdNCbWRczS696DpwGrKhR7BngG8Hom2OAPe6+tdG1PRDt0ouIhDRl1E1f4Ekzq1rPQ+7+gpldDuDudwJzgVnAOqAYuKRp1a2frowVEQlrdNC7+3rgiFrm35nw3IErG7sNERFpukhdGatBNyIiYdEK+taugIhIGxSpoBcRkbBIBb26bkREwqIV9Oq8EREJiVbQK+dFREIiFfQiIhIWqaDXDr2ISFikgl59NyIiYdEKehERCYlU0Gt/XkQkLFpBr6QXEQmJVNCLiEhYpIJetxIUEQmLVtC3dgVERNqgptxharCZvWZmq8xspZldVUuZGWa2x8yWBo+fN626Dae9exGRmKbcYaoc+JG7Lw5uKbjIzF529w9rlHvL3c9qwnYaTNkuIhLW6D16d9/q7ouD54XAKmBgc1WsUXVKfK7QFxEBmqmP3syGAUcC79eyeJqZLTOz581sbD3rmG1mWWaWlZeX1+Q6KedFRGKaHPRm1hV4HPi+uxfUWLwYGOruRwB/Bp6qaz3ufpe7T3b3yZmZmY2qi/rlRUTCmhT0ZpZKLOQfdPcnai539wJ3LwqezwVSzax3U7bZUAp9EZGYpoy6MeDvwCp3v7WOMv2CcpjZlGB7Oxu7zYNRoaAXEQGaNurmOODrwAdmtjSYdz0wBMDd7wTOB64ws3JgH3CBt+CuduKa84vL6NstOXheSnrHVJKTrKU2LSLSZjU66N39baDe5HT324DbGruNg5V4K8G8wv307daRwpIyJt7wMpdNH8F1sw7/rKoiItJmROrK2EQ7ivYDUFhSDsDji7NbszoiIq0mUkGf2HVz5xsfs3lXMcWlsaAvLa9spVqJiLSuyAR9WUUlv3t+dXz6vfW7+M4DWRTtrwCgtEJBLyL/mSIT9KnJ4aas3lbIq6tyASir0CgcEfnPFJmgT3T/t6ZgwWniP89bB0BFZdOCfsEnuzjhltdYtjmfov3lTa3iQSmvqGTp5vwmt6ExikvLWbe96DPfbkWlk1tQ8plv9+UPczn11jf4w4trmPvBVl2PIZHQlOGVbc64gd1YsaWAY0b0ZP1vZ3HPOxu48dlPv2Pt0azN5OSXcNUpIw963Te/sJqNO4s55/Z36JSazKWfG06fYFTPcYf05ojBGc3Ykk89viibB+ZvYFn2Hs6c0J/xA7tz3pEDeeOjPH4zdxVvXn0i3TqmNvt2yyoqWZlTwKX3L2RHUSm3f3USYwZ0Y2jPzlxy30LOmzSQcya2zFcb7Sjaz3f/uZgFG3Zx8bShFO4v51vHDadgXxnzVm/n+lmHk9QCQ2W37tnHdx7IAmDt9tgOQpLB+EEZzDgsk1PH9GXcwO7Nvt0qH+cVsXRTPukdU3jug6389gvj2V1cygfZezhjfP8W2y7ASyu3kZJsrM/by3GH9uawvun84JGlfGnyID43snFXqjfE5l3FLPhkF1OG92RZdj5nju9PXtF+Nu0sZvKwni22XYDX12znsL7pbNpVzOh+6WR07sCabYUM792FDiktsw9cUFLGyytz+dtb6/npmWPILSjhvEkDWbW1kDW5BXzhyEEtsl1ri3sskydP9qysrIN+XUFJGSu27OHYQ2IX3760chuz/7EoVO6J7x7LpCE9GrzelTl7OPf2dyircM6a0J+Pcgv5KLf6Xu5RQ3vwr8umNetY/fKKSg79yfP1lklPS+G960+mS1rzfmbPWbCJ6574oN4yj14+jaNb4J9x2LXP1bv85i9O4MtHD2727d75xsfc9PxqDu/fDQMmDOrOwws3Vyvz1JXHMbEFPtQfen8TP3t6ReiorXOHZIpLK7jvkqOZMapPs293yabd/Pix5aGjtoumDuHB9zcB8NGvz2iR4PuvOUt4dnkOdR2ovvLD6RzaJ73Zt7t6WwG/eW4Vb63dUW3++UcN4rFF2Xxl8mB+f/6EZt9uZaVz5I0vs2dfWbX5Rw3twaKNuwF477qT6de9Y6PWb2aL3H1ybcsi1XXTrWNqPOQBBvXoHH8+a3w/fnDKYfTonMqfX10bn19Z6fwrazMlZRV1rveXz6wko3MHlvzsVG776iQemT0tVGbRxt3kFpTU2t1QWenc/dZ6dgZDPhtq9bZCAPp378hdXz+K4b278JMa1wIU7i9nzoJNB7Xehli4YRcA154xmuMO7cUZ4/qFyjyW1fxDVnfvLY0/v+m88dx8/gSOHJJRrcxPn15R79+rsdbnFdG7axrPX/U55l71Oa6eOTpU5sH3NobmrdtexLsf7wjNb6g9+8r4+dMrGNU3nQunDGZIz84M790FgOLSWDt//NjyFulGenppDpt3FXPhlCHV5leFPMC81dubfbs7ivbzzLIcBmR0YlTf2sN8zoLNtc5vqocXbOattTuYNqJXtfmPLYq9nx/J2twi3aRb8vfFQ350v1ib09NS4iEP8NwHW5t9uxCxrpuaBvfsFH9++1cnYWakJBu3vLiGO17/mKkjerKzqJSrH1vOx3lFXHXySDp3iP1KCkvKuO+dDVxy/HCWbMrnO9NH0KNLBwB6dOnAR78+gx88spQTR/chvWMKl/1jEVc+tJglm/K595KjOTFh72vRpt38+rlVLNmUz0/OPJw9+8o4vH83Xly5jaKSck4c3Qd3p1fXNADeWptH17QUlm3OB+DxK45lQEYnThsbC9vD+qVz27y13HvJFI7//Tw27izm/fU7yUxPY0v+PhZ+sosfnjYKgL37y9lXVkHvYN0N9UH2Hk4clcnlJxzC5SccAsSOMGb+31ucNaE/Cz7ZxeptNb/DrumqPtwe+NYUph8W6zKYMSqTKb95FYh98Nz0/GrW5hYxflDt3Sj7yysoq3C6HuRRzvq8vYzI7BKf7tmlA4/MPoav3PUeU4f3JKNzKu99Ev4Gj1NufQOADTedeVDbq/L22h2UVzo3njuWo4b2xN3ZVlDCsTfNwx0unjaU++dvpGBfOd07N2833eJNu5k4OIPfnTees48YwKF9urIyZw/fvHchZ47vz3MfbGXV1gJm1vJB3xRV7+1bvzyRI4dkkJO/j7zC/Zx/53wAxg7oxmtrtvOzs8Y063Yh1uZjRvRkzuxjeGZZDkcOzuAvr6+r9sGyelsBYwc0bzfdR7mx9/bjVxzLhEHd2banhO6dU5nwy5fiZRZ8spNvHz+8WbcLEQ/69I6p/PrccSzZlE/wlTt8Y9pQnlqyhd+/EBuKecM5sW9OfnzRFv76xnoA5l93En96dR1zFmwit7CE8kpnfI2+2Q4pSdx+0SQAlgZv2iWbYj9/+uQKZo3vx+h+3Xh+xVamDI91b6zJLeTYm+bFt3FZ0K3UNS2Fov3lPHTpVI4c0oOv/30BAAO6d4w9MjqR6ITDMjkhCMGeXTrw2prt/OO9jZjB8F5d2LSrmNPG9uOwvul8676FvP/JLtb/dhb5+8ro0TmV3cVlXPv4cn51zli6pKWwNreQSUN6sLu4jPvf3cDFxw5jXV4Rnz9iQLXtpiQn8coPTwDgxmc/5MH3N/Lamu08tWQLN5w9rllCqOrDY3T/T/fy+qR3ZPkvT2NtbiE9u6Rx0/OrWbWtoM6g/+Y9C5m/fiffnXEIs6ePIKNzhwNu191Zl1cUOnKZOqIX8350AgMyOnH3W+t5cWUuzy7PYVivLqH++tLyyngXh7vjTr3nEv4xfwPDendhRc4eUpONCYMyADAz+nfvxKobZrJtTwkrcvZw//yNbC3Y16xBX1HprN5WyMXThgIw7ZDYHu6MUX2Yf91JZHZN492Pd8QvPmxOH+bE/s5jB3QjNTmJob26MLRXFz684XR2FJbyr6zN/OX1dVRUerN3h67aWsC3jouF6dnBe/x3503g2EN6M7hnZ869/R0Wb8pv9qBfG3SPHdqnK6nJSQzuGetxeOzyaSzcsJu12wt5fU0e7h7Pq+YS6aAH+NoxQ/naMUPj0+kdU/n3/zue7z64mHmrt/PbuasAqr2Zp/1uXvz5P9/bRNe0lHhY16ZPevW95S35+/jbW5/Ep19ZFTv0TewHTdxG1Sier95d/ev8c/aUxN+IdenVpQMLN8QO/dxh/Y69AJz157erlTvrz2/z4dYCZozKZOLgDF76MJct+ftYGfzD/eLzY7j3nQ1s2lXMsux83Al1mSQa0rMzJWWV/PjR5ewo2k9yknHOxIGMG9CNXXtLObRPV55dvpW31uaxelsh93zzaLp3SuXhhZuprHTOGN+PNz/awYCMjhx7SG9O/983mTK8J6XllfTq0oHMGkcg3TqmctTQnlRUOqnBScO6QmD++the919e/5jdxWXceM5YHHhicTZfOHJQtf7m1dsK+O3c1Vw/azT5xWWMqeWfe0RmVwD6d4994H7voSWx7Vx3UnwewIdbC/jhI0u55UsTmLNgMzn5+3jw0qks3pRPcpJV69svKavgZ0+vBOCUw/swonfX0BDhjqnJDOvdhZ1Bd9bW/BJG9+tW599k4869nHDL6wc8j7B5VzH3vrOBrx0zhNLySg4J2peoql29uqaxs6g0tPxAsncXk5qcRN9u1fubc/L3kd4xhfU79jKge8fQuaXOHVIY0iuFPt3SqHTYtbeUzPSDOxrNK9xf62vKKirJ3r2PsgrnkD7hNn/+iAFUBu+v7N3FoeW79pZSWl5JZnoaTy7Zwuh+6Ywb2D0UzGUVlSSZxd+bu/aW0rlDMh/lFtK3WxrdO1X/sJ48rCeTh/Xkw5wCLpo6BHdo5pyPftDXpmNqMn+5aBJf/ut8lmfvOWD573xuRL1dH4lvqrOPGMAzy3JCZe782iR+M3cVpx7ej8P6duXaek50JidZvI/wD186ot669WjA3irEQgjg9TV5vL4mdmOXqpAH+NW/Px2d9PqaPA7t07XeE619u8XaXPUB+cTiLTyxeAsDunckZ08JU4f35P1PdsXLT/71Kwzv3YVPgg+iXzyzMr7sG9OGsia3kDW5hXRNS+GIwd3r3KNJTjL6de/Iv5fl8Pe313PL+Udw7pF1j/6Zs2ATSzbt5kuTB3Pjsx+StWE384NurpvOm8CX7pxPYUk5ZcGV0zWP3BL1z6geWv/96DIevPSY+PS/sjazfsdeLvzb+/Ersed/vDP+Af7NY4dx37sbuPHccaQlfNi8s24nJx9e94nW/sHJuZw9+3h33Q4mDe1Bx9TkamXWbCvkT/Ni554uvmcBt5w/gYE9OvHFO97lme8dz6GZXVm9rZAxA7rxnQeyWL2tMN6VMKKWoK/Su2sHdhTtZ2XOHtZtLwqNtNpXWsEtL65h1979DOrRmeNH9mbq8J4c//vXALj3m0fzyY69zBiVSe/0NI69aR5HDslgZ1EpwxO6yWqq+qDfXljCjqL9jOzTlZQaH4R/e3M9Ty/bwrgB3TlpdB+6d0olZ88+fvDIMh741hSeX7GV8grnxnPHMWfBJn717w/55edjXUGH1LHtpOD9tTW/hLW5heTsKYkfPc+45TUKSsp56DtT+e9Hl9EhJYn/+8pEbnz2Q267aBKPZm1mYEYn7npzPQUl5dxx0SQ27irmpudXc8rhfXllVS7HHdqr1u0CjBlQ94d4U/1HBj3Ewv4Xnx/LF+94l2vPGE327mJ6d03jj6/E/lmW/fw0fvToUl5ZtT1+SFuX1OQkenXpwM69pfzmC+O4+fwJHHvTPHYFe2Kv/ugEDsnsyulj+8UDbMPOYrbu2ceXJw/mmseXc8HRg/nDSx9x+ti+/ODUw5j5x7cADjjaoVfXWNB/bmRvVm0t4KihPXhxZewisS4dkjEzZo7rR4/Oqfz49NH86t8refD9TYzp3y0e/lXOHN+f19dsZ29pBf992mGhMEmUuKc2cXBGvPsqZ0/sZHRiyFepCvmaHpj/6QnOov3lXDR1aK3lqgzo3im+/scXZzNxcAaDenTiiSVbmFLLh9PqbYXxYbaPBifcsnfv4/Q/vhkvM3/9TqYM78m4ev7ZBiTsvVeFduLIpIeCE5iJX7dx2T8/HfV137sbAPjZUyuqrXdfWQWXTT+kzu32SU8jyeCvb6xn065ivnTUIM46YgBHD+tBWbnTvXMq37x3AVuD3/2efWXM/sciPjeyNyVllfz0yRUsCE6u9+/eMV7u7XWxE8gja9m7rdK7axortuzhzD/FjhBPG9OPDilJuDsV7ry+Zjv3vPPp0ettr63j+lmfnsS+5L6FANzw7KfrrOriPOXwvnW3OdiRmP/xTn793CouPX44Pz1rDO7Oux/v5OhhPfmfl9dQUlbJii0F8dFRVW35xj0L4uuq+psD/DLYoantKKZK/+6d2LpnH6f+b+z9sfJXp9MlLYWC4Huzqt7rpeWVXPHgYgC+fvf77C2tPkCgahnAK8GFm+MHZtS53Zb0Hxv0EBvW9NbVJzKoR6d4AB+S2ZXyykq6d07l9osmseCTXRw97MBDMV/6wXQ+2LKH9GBMe9WokJvPnxB/UyXupV57xqf/DG9fcxKl5ZX06daRs48YQMfUZK6eOYqBNfrma9OrS+wf4tA+Xbnvkil8lFsYD/qVN8wMHVb+8uyxTD8skxNH9WFL/j46pSZz9ePLefOjPH597jh27t3Pv5dt5cTR9Q/lSxwC9sevTCQzPY2xv3gRgCMGZ/Dt44eTvbuYf87fyC/OHssph/fluw8uYn95JRWVHhraNqJ3l3i306wDjBnvn7Dtt9buYMYfXqdDSlKd32c0MKMTW/L3MbJP13g/aeK6qoLvn9+eGtprrFY2oyM9OqeS0bkD35g2lPve3VDviKeqD4PadE1L4YoZh3DLi2sY1KNTnecbIHZupE96RzbtinUnPLoom0cXZXNon66s216EWe33SK76HVeFPBBva5XrZ42ODzKoTWZ6Ght2ftqNcfjPX2BM/24Mz+zCO+t2kJIU/n39du7q0Lya0tNSuHrmqLq32zX2N34o+P3e/fYn3P32J/z+i+O55vEPGNU3nZKy8N+75t+3NledPLLe8zYDMzrFr6gHGPuLF7kmYQTWzS+sqVb+6GE94t2ntenWMfYhkd4xhf86+dAD1q8l/EcHPRA/IVIl8QRkWkpygy8W6dU1rdo456phcWMbeDjWISWJL0/+dGz4d2c07A1xwZTBFO0v58uTB5OcZPE9/KnBOYWaXSCpyUmcHozeqRrCd+fXJpGSlESHlCR6dOnAD0498NjlzK5p8T27wT07V+sr/8254+InKhPb8devT672wbN0cz4X3DWfG84exxePGsRVDy9p0Bj1cQO789TSHH7zhXHkFuznT6+urRbyJ4/uExsmuWIrN5wzjj7d0vj50yv5vwuOpKyikvLKSi7/52LyCvcz70czeHV1Ln27dTzg0VNaSjLvX38KKUlGUpJx3yVH8817Y3usXz9mKCeN7sO2ghKue+IDzprQn6tnjuLjvCIGZnRi7MDubNixl49yC3lr7Q6umHEIX548mLfX7uDMCQe+GKpf945sKyhhenDh1s+eWhE/51Mz5Ef3S+cb04Zx/ZMf8OPTR5FfXMoph/fl+ic/4OO8vZwzcQCbdhWzZFM+Z06o/xxQ1Xsk0YdbC+JHgzV/Z8/91/Gc+ae3yeicyn2XTOGuNz9m7gfbALhs+gimH5bJ5f9YxOzpI+o/YuyeRnJS7FxMop88GTsaWhN0O1W54ZyxbNtTwl9e/5gbzx1HapKxbnsRd78dO9q495KjufmFNWzYsZeLjx1Wb5tH9O7CkyXVr36vGrxRU3rHFP556VRufmENfbul8e3jR7B1zz7ueP1jHnx/Ew/PPobBPTvz3/9axleOHhwf1feZi40OaNwDmAmsAdYB19ay3IA/BcuXA5Mast6jjjrK27sTbp7nQ6951veXVXzm2567PMfz95a2+HZ2791fbTun3vq6D73mWS8rb3ibKysrD3q7FRWVvnd/WXz6kYWbfOg1z/rQa571o258qUHryCss8fzipv+Ohl0b2+5bH+XF13varW/4mm0Fdb5mR2HJQW/ni395x4de86z/4cXV7u7+5OJsH3rNsz71N6/4pp17/emlW3zFlnxfvjk//jvNyS+uto6dRft908697u5eVl7h2burL6/N22vz4r/bopIy31daHp+++tFlnldY4ruK9vvF97wf397GHXt9S8K6KysrfcOOomrTDTHjltd86DXP+k+eXO6l5RX+nfsX+tBrnvWL/vae7yra7xt37PXz/vKOn3brG+7uXl5R6W+vzau2/o+2FXjunn3x5QX7Dvw3f3XVtngb84tLfW1uQXx6+eZ8L95f7pt27vXL/5HleXX8LSsrKz+T/8FEQJbXkamN/ngxs2TgduBUIBtYaGbPuPuHCcXOAEYGj6nAHcHPyJsz+xg+2bG3xS6lrk9LXy5fpebh75zvHMOOotJ6uz9qaswwsqQkq7ZnNKZ/7Khp1vh+3P7VSQ1ax8FeV1CXv37tKJZszo+fZOvdNY0XfzC93tf0asS2jxySQdbG3fGToaOCC25OOrwPg3t2Dh2ZAtVGBEFsKG7PoJsmJTmpQV2DhwZ93gMzOoVGyPzqnLHxvfL7LpkSnz+kV/W6mBlDe3WpNt0QKcFR4kmj+5CanMRXpw7hpQ9zOXF0H3p06UCPLh14/Ipj4+WTk4zjDq1+S+qRCRdjJSdZvGu1PuMHZpCSZBzevxvdO6VWGyUzdkA3kpKMwT07c8fXjqpzHWbW7Nc8NEWjvwLBzKYBv3T304Pp6wDc/XcJZf4KvO7uc4LpNcAMd6/38q/GfgWC/Gdyd+Ys2MwZ4/rV29/cnpWUVVCwr4w+CSfB3/goj2NG9CQtpe4ukOYwb3UuRw3tGQ+8JZt2k5Nf0qAup6ZYuGEXCzfs4ooTDsHMcHf+vXwrpx7el04dWrbNeYX76dE5Nb7TsnlXMXtLy+sd3tra6vsKhKYE/fnATHe/NJj+OjDV3b+XUOZZ4CaP3XYQM3sVuMbdQyluZrOB2QBDhgw5auPG8KXmIiJSu5b6rpvajr9qfmo0pExspvtd7j7Z3SdnZrbct+WJiPynaUrQZwOJXyE4CKh5pVBDyoiISAtqStAvBEaa2XAz6wBcADxTo8wzwDcs5hhgz4H650VEpHk1etSNu5eb2feAF4Fk4B53X2lmlwfL7wTmArOIDa8sBi5pepVFRORgNGn0vrvPJRbmifPuTHjuwJVN2YaIiDRNpG48IiIiYQp6EZGIU9CLiERcm7w5uJnlAY29Yqo30PgbeLYNakPboDa0HVFoR0u3Yai713oRUpsM+qYws6y6rg5rL9SGtkFtaDui0I7WbIO6bkREIk5BLyIScVEM+rtauwLNQG1oG9SGtiMK7Wi1NkSuj15ERKqL4h69iIgkUNCLiERcZILezGaa2RozW2dm17Z2fepjZveY2XYzW5Ewr6eZvWxma4OfPRKWXRe0a42Znd46tf6UmQ02s9fMbJWZrTSzq4L57akNHc1sgZktC9rwq2B+u2lDFTNLNrMlwY1+2msbNpjZB2a21Myygnntqh1mlmFmj5nZ6uB/Y1qbaUNdN5NtTw9i3575MTAC6AAsA8a0dr3qqe90YBKwImHezQQ3WAeuBX4fPB8TtCcNGB60M7mV69+f4EbvQDrwUVDP9tQGA7oGz1OB94Fj2lMbEtryQ+Ah4Nn29l5KaMMGoHeNee2qHcD9wKXB8w5ARltpQ1T26KcA69x9vbuXAg8D57Rynerk7m8Cu2rMPofYG4Xg57kJ8x929/3u/gmxr3yeQity963uvjh4XgisAgbSvtrg7l4UTKYGD6cdtQHAzAYBZwJ3J8xuV22oR7tph5l1I7YD93cAdy9193zaSBuiEvQDgc0J09nBvPakrwc3ZQl+9gnmt+m2mdkw4Ehie8Ttqg1Bl8dSYDvwsru3uzYAfwSuBioT5rW3NkDsQ/YlM1sU3D8a2lc7RgB5wL1BN9rdZtaFNtKGqAR9g+9N2w612baZWVfgceD77l5QX9Fa5rV6G9y9wt0nErvF5RQzG1dP8TbXBjM7C9ju7osa+pJa5rX63yFwnLtPAs4ArjSz6fWUbYvtSCHWHXuHux8J7CXWVVOXz7QNUQn6KNybNtfM+gMEP7cH89tk28wslVjIP+juTwSz21UbqgSH2K8DM2lfbTgOONvMNhDrrjzJzP5J+2oDAO6eE/zcDjxJrBujPbUjG8gOjgoBHiMW/G2iDVEJ+obcv7atewa4OHh+MfB0wvwLzCzNzIYDI4EFrVC/ODMzYn2Rq9z91oRF7akNmWaWETzvBJwCrKYdtcHdr3P3Qe4+jNh7fp67f4121AYAM+tiZulVz4HTgBW0o3a4+zZgs5mNCmadDHxIW2lDa5+pbq4HsXvTfkTs7PVPWrs+B6jrHGArUEbsk/3bQC/gVWBt8LNnQvmfBO1aA5zRBup/PLHDzOXA0uAxq521YQKwJGjDCuDnwfx204Ya7ZnBp6Nu2lUbiPVvLwseK6v+f9thOyYCWcF76imgR1tpg74CQUQk4qLSdSMiInVQ0IuIRJyCXkQk4hT0IiIRp6AXEYk4Bb2ISMQp6EVEIu7/A+yCDMJx6vZYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8098e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7466536164283752\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred_train = multimodal(X_train).argmax(axis=1)\n",
    "accuracy = (y_pred_train == train_labels.to(\"cuda\")).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c349257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "            other_relevant_information       0.84      0.61      0.71      1279\n",
      "                  affected_individuals       0.00      0.00      0.00        71\n",
      "rescue_volunteering_or_donation_effort       0.55      0.66      0.60       912\n",
      "     infrastructure_and_utility_damage       0.00      0.00      0.00       612\n",
      "                      not_humanitarian       0.78      0.98      0.87      3252\n",
      "\n",
      "                              accuracy                           0.75      6126\n",
      "                             macro avg       0.43      0.45      0.44      6126\n",
      "                          weighted avg       0.67      0.75      0.70      6126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/pace-apps/manual/packages/anaconda-individual/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/pace-apps/manual/packages/anaconda-individual/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/pace-apps/manual/packages/anaconda-individual/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_names=['other_relevant_information', 'affected_individuals', 'rescue_volunteering_or_donation_effort', \n",
    "              'infrastructure_and_utility_damage', 'not_humanitarian']\n",
    "print(classification_report(train_labels, y_pred_train.cpu(), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee09053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.39790576696395874\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = multimodal(X_test).argmax(axis=1)\n",
    "accuracy = (y_pred == test_labels.to(\"cuda\")).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01f50704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "            other_relevant_information       0.45      0.84      0.58       235\n",
      "                  affected_individuals       0.00      0.00      0.00         9\n",
      "rescue_volunteering_or_donation_effort       0.01      0.02      0.02       126\n",
      "     infrastructure_and_utility_damage       0.00      0.00      0.00        81\n",
      "                      not_humanitarian       0.59      0.36      0.44       504\n",
      "\n",
      "                              accuracy                           0.40       955\n",
      "                             macro avg       0.21      0.24      0.21       955\n",
      "                          weighted avg       0.42      0.40      0.38       955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/pace-apps/manual/packages/anaconda-individual/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/pace-apps/manual/packages/anaconda-individual/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/pace-apps/manual/packages/anaconda-individual/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_names=['other_relevant_information', 'affected_individuals', 'rescue_volunteering_or_donation_effort', \n",
    "              'infrastructure_and_utility_damage', 'not_humanitarian']\n",
    "print(classification_report(test_labels, y_pred.cpu(), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82cd2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
